{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample = 2\n",
    "output_size = 160//downsample\n",
    "\n",
    "def preprocess(frame):\n",
    "    '''from karpathy.'''\n",
    "    I = frame\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::downsample,::downsample,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    tensor = torch.from_numpy(I).float()\n",
    "    return tensor.unsqueeze(0).unsqueeze(0) #BCHW\n",
    "\n",
    "# def clip_grads(net, low=-10, high=10):\n",
    "#     \"\"\"Gradient clipping to the range [low, high].\"\"\"\n",
    "#     parameters = [param for param in net.parameters()\n",
    "#                   if param.grad is not None]\n",
    "#     for p in parameters:\n",
    "#         p.grad.data.clamp_(low, high)\n",
    "        \n",
    "if torch.cuda.is_available():\n",
    "    def to_var(x, requires_grad=False, gpu=None):\n",
    "        x = x.cuda(gpu)\n",
    "        return Variable(x, requires_grad=requires_grad)\n",
    "else:\n",
    "    def to_var(x, requires_grad=False, vgpu=None):\n",
    "        return Variable(x, requires_grad=requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''very similar to Nature DQN.'''\n",
    "    def __init__(self, action_n, input_shape=(1,80,80)):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(nn.Conv2d(input_shape[0],16,kernel_size=8, stride=2),nn.ReLU(),\n",
    "                                  nn.Conv2d(16,32,kernel_size=4, stride=2),nn.ReLU())\n",
    "        flatten_size = self._get_flatten_size(input_shape)\n",
    "        self.fc = nn.Linear(flatten_size, action_n)\n",
    "    \n",
    "    def _get_flatten_size(self, shape):\n",
    "        x = Variable(torch.rand(1, *shape))\n",
    "        output_feat = self.conv(x)\n",
    "        n_size = output_feat.view(-1).size(0)\n",
    "        return n_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x)\n",
    "        logit = self.fc(feat.view(feat.size(0),-1))\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net(env.action_space.n, input_shape=(1,output_size,output_size))\n",
    "\n",
    "weights_path = \"episode9400.pth\"\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    weights = torch.load(weights_path)\n",
    "else:\n",
    "    weights = torch.load(weights_path, map_location={'cuda:0': 'cpu'})\n",
    "net.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:13<11:05, 73.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [02:21<09:36, 72.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [03:28<08:12, 70.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [04:28<06:44, 67.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [05:49<05:57, 71.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 -2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [06:54<04:38, 69.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 -12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [07:54<03:20, 66.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 -11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [08:48<02:05, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 -17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [09:52<01:03, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 -10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [09:59<00:00, 46.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 -6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for episode in trange(10):\n",
    "    frame = env.reset()\n",
    "    last_obs = preprocess(frame)\n",
    "    curr_obs = preprocess(frame)\n",
    "    total_reward = 0\n",
    "    for step in range(100000): # not exceed 10000 steps\n",
    "        with torch.no_grad():\n",
    "            prob = net(to_var(curr_obs-last_obs))\n",
    "            _, action_ = prob.max(dim=1)\n",
    "            action = action_.data[0]\n",
    "        frame, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        last_obs = curr_obs\n",
    "        curr_obs = preprocess(frame)\n",
    "        total_reward+=reward\n",
    "        if done:\n",
    "             break\n",
    "    if step==100000:\n",
    "        print(\"not enough!!!!!!!!!!!!!!!\")\n",
    "    print(episode, total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
